{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8XRRYoWoEJa"
   },
   "source": [
    "# AITEX FABRIC IMAGE DATABASE\n",
    "- https://www.aitex.es/afid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pv5HRzuxA35r"
   },
   "source": [
    "## Data\n",
    "- The textile fabric database consists of 245 images of 7 different fabrics\n",
    "- Images have a size of 4096×256 pixels\n",
    "- There are 140 defect-free images, 20 for each type of  fabric\n",
    "- With different types of defects, there are 105 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GH_Dfz8Potpp"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfgcaqvcpBPh",
    "outputId": "4a7e9393-db42-41a5-951d-7ea57644b23b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cE8aNhdHsaAd",
    "outputId": "e8ff4b75-6e8c-46bc-e04a-7b0f3c4761bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/colab_notebook/image\n"
     ]
    }
   ],
   "source": [
    "% cd ./drive/MyDrive/colab_notebook/image/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D39C5OzCp5bb"
   },
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uilx5tjqoZGD",
    "outputId": "fb4336e4-7518-40a3-a507-d377cbc3bb43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcRabXytoZNt"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thx0NXzDoZQe"
   },
   "outputs": [],
   "source": [
    "PATH_DEFECT = 'dataset/Defect_images/'\n",
    "PATH_MASK = 'dataset/Mask_images/'\n",
    "PATH_NODEFECT = 'dataset/NODefect_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OM1p7A_9oZVL"
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
    "mask_list = glob.glob(PATH_MASK + '*.png')\n",
    "pass_list = glob.glob(PATH_NODEFECT + '**/*.png')\n",
    "\n",
    "# Match defect-mask pairs\n",
    "new_defect_list = list()\n",
    "new_mask_list = list()\n",
    "for defect in defect_list:\n",
    "    num = defect.split('/')[-1].split('_')[0]\n",
    "    for mask in mask_list:\n",
    "        num_mask = mask.split('/')[-1].split('_')[0]\n",
    "        if num == num_mask:\n",
    "            new_defect_list.append(defect)\n",
    "            new_mask_list.append(mask)\n",
    "            break\n",
    "defect_list = new_defect_list\n",
    "mask_list = new_mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNCvCa2SoZdv"
   },
   "outputs": [],
   "source": [
    "# train dataset\n",
    "if os.path.exists('dataset/OK') is False:\n",
    "    os.mkdir('dataset/OK')\n",
    "if os.path.exists('dataset/FAIL') is False:\n",
    "    os.mkdir('dataset/FAIL')\n",
    "if os.path.exists('dataset/MASK') is False:\n",
    "    os.mkdir('dataset/MASK')\n",
    "\n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 3:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/OK/%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('dataset/FAIL/%04d.png' % idx, patch)\n",
    "    cv2.imwrite('dataset/MASK/%04d.png' % idx, patch_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efM531yNE_Ml"
   },
   "outputs": [],
   "source": [
    "# The test dataset\n",
    "if os.path.exists('data/') is False:\n",
    "    os.mkdir('data/')\n",
    "if os.path.exists('tfrecords/') is False:\n",
    "    os.mkdir('tfrecords/')\n",
    "if os.path.exists('model/') is False:\n",
    "    os.mkdir('model/')\n",
    "if os.path.exists('data/input_data') is False:\n",
    "    os.mkdir('data/input_data')\n",
    "if os.path.exists('data/output_csv') is False:\n",
    "    os.mkdir('data/output_csv')\n",
    "    \n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 5:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('data/input_data/ok_%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('data/input_data/fail_%04d.png' % idx, patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJUhxv-wvJoj"
   },
   "source": [
    "## Data Preprocessing\n",
    "* TFRecord Builder\n",
    "  * Data Serialization to learn faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCUli3DWoZln"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ofq6iwqPvkgL"
   },
   "source": [
    "Paths and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-DE-4jCoZoO"
   },
   "outputs": [],
   "source": [
    "DATASET_OK_PATTERN = 'dataset/OK/*.png'\n",
    "DATASET_FAIL_PATTERN = 'dataset/FAIL/*.png'\n",
    "\n",
    "# to serialize the data into binary\n",
    "TFRECORD_PATH = 'tfrecords/'\n",
    "IMAGE_PER_TFRECORD = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NDbQNC9vspc"
   },
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRtQeWkTvp0x"
   },
   "outputs": [],
   "source": [
    "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
    "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
    "\n",
    "num_ok = len(ok_list)\n",
    "num_fail = len(fail_list)\n",
    "\n",
    "# Oversampling\n",
    "# to make the number of fail datas equal to number of ok datas\n",
    "fail_list_new = list()\n",
    "for _ in range(num_ok // num_fail):\n",
    "    fail_list_new += fail_list\n",
    "fail_list_new += fail_list[:num_ok % num_fail]\n",
    "fail_list = fail_list_new\n",
    "\n",
    "ok_label = [0] * len(ok_list)\n",
    "fail_label = [1] * len(fail_list)\n",
    "\n",
    "file_list = ok_list + fail_list\n",
    "label_list = ok_label + fail_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qD7xUPOvygS"
   },
   "source": [
    "TFRecord functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdLid62-vp3F"
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def image_example(image_string, label):\n",
    "    image_shape = tf.image.decode_image(image_string).shape\n",
    "\n",
    "    feature = {\n",
    "        'height': _int64_feature(image_shape[0]),\n",
    "        'width': _int64_feature(image_shape[1]),\n",
    "        'depth': _int64_feature(image_shape[2]),\n",
    "        'label': _int64_feature(label),\n",
    "        'image_raw': _bytes_feature(image_string),\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82cnCjI2v2-1"
   },
   "source": [
    "Write TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMD_HWMYvp5W"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(TFRECORD_PATH) is False:\n",
    "    os.mkdir(TFRECORD_PATH)\n",
    "    \n",
    "num_tfrecords = len(file_list) // IMAGE_PER_TFRECORD\n",
    "if len(file_list) % IMAGE_PER_TFRECORD != 0:\n",
    "    num_tfrecords += 1\n",
    "    \n",
    "for idx in range(num_tfrecords):\n",
    "    idx0 = idx * IMAGE_PER_TFRECORD\n",
    "    idx1 = idx0 + IMAGE_PER_TFRECORD\n",
    "    record_file = TFRECORD_PATH + '%05d.tfrecords' % idx\n",
    "    with tf.io.TFRecordWriter(record_file) as writer:\n",
    "        for filename, label in zip(file_list[idx0:idx1],\n",
    "                                  label_list[idx0:idx1]):\n",
    "            image_string = open(filename, 'rb').read()\n",
    "            tf_example = image_example(image_string, label)\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiPSzGpQzyfD"
   },
   "source": [
    "## Model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFf-dHsjvp7w",
    "outputId": "095d09e3-b51b-4547-bfa6-69133ac8ab15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 28.2 MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20 kB 23.2 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30 kB 11.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 40 kB 9.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 51 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 61 kB 5.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71 kB 6.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 81 kB 6.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 92 kB 4.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 102 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 112 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 122 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 133 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 143 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 153 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 163 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 174 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 184 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 194 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 204 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 215 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 225 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 235 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 245 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 256 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 266 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 276 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 286 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 296 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 307 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 317 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 327 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 337 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 348 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 358 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 368 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 378 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 389 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 399 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 409 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 419 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 430 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 440 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 450 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 460 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 471 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 481 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 491 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 501 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 512 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 522 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 532 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 542 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 552 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 563 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 573 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 583 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 593 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 604 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 614 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 624 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 634 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 645 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 655 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 665 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 675 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 686 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 696 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 706 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 716 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 727 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 737 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 747 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 757 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 768 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 778 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 788 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 798 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 808 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 819 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 829 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 839 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 849 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 860 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 870 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 880 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 890 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 901 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 911 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 921 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 931 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 942 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 952 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 962 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 972 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 983 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 993 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.0 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 1.0 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.0 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.0 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 1.0 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.1 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.1 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.1 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.1 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.1 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
      "Installing collected packages: tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.14.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spJgRgLQvp9_"
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Concatenate, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK3AvSr_0uL2"
   },
   "source": [
    "Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Z4WIx1xvqAY"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "RESULT_SAVE_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlPD8Cxz1TLG"
   },
   "source": [
    "### Function define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEi_Gt0M02pP"
   },
   "source": [
    "Inception-based model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89_LSdWVvqC0"
   },
   "outputs": [],
   "source": [
    "def Model():\n",
    "    def inception(filters):\n",
    "        def subnetwork(x):\n",
    "            h1 = Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "            h1 = MaxPool2D()(h1)\n",
    "            \n",
    "            h2 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
    "            h2 = Conv2D(filters, (3, 3), padding='same', activation='relu')(h2)\n",
    "            h2 = MaxPool2D()(h2)\n",
    "            \n",
    "            h3 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
    "            h3 = Conv2D(filters, (5, 5), padding='same', activation='relu')(h3)\n",
    "            h3 = MaxPool2D()(h3)\n",
    "            return Concatenate()([h1, h2, h3])\n",
    "        return subnetwork\n",
    "    \n",
    "    x = tf.keras.Input(shape=(256, 256, 3))\n",
    "    h = inception(16)(x)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = Flatten()(h)\n",
    "    h = Dense(1024, activation='relu')(h)\n",
    "    y = Dense(1, activation='sigmoid')(h)\n",
    "    return tf.keras.Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnc8UpUp1FW7"
   },
   "source": [
    "Data preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_HkqbzAvqFY"
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hd_Tcm3L1Jsq"
   },
   "source": [
    "Data Augmentation function\n",
    "- do filp, rotate, translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBqn5lBLvqHv"
   },
   "outputs": [],
   "source": [
    "def augmentation(img, label):\n",
    "    def flip(x):\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "        x = tf.image.random_flip_up_down(x)\n",
    "        return x\n",
    "    \n",
    "    def rotate(x):\n",
    "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
    "                   lambda: tfa.image.rotate(x,\n",
    "                                       tf.random.uniform(shape=[], minval=0.0, maxval=360.0, dtype=tf.float32),\n",
    "                                       interpolation='BILINEAR'),\n",
    "                   lambda: x)\n",
    "        return x\n",
    "    \n",
    "    def translation(x):\n",
    "        dx = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
    "        dy = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
    "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
    "                    lambda: tfa.image.transform(x,\n",
    "                                                [0, 0, dx, 0, 0, dy, 0, 0],\n",
    "                                                interpolation='BILINEAR'),\n",
    "                    lambda: x)\n",
    "        return x\n",
    "    \n",
    "    img = flip(img)\n",
    "    img = rotate(img)\n",
    "    img = translation(img)\n",
    "           \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoRfVv1w1ZaJ"
   },
   "source": [
    "Load TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFleuromvqKA"
   },
   "outputs": [],
   "source": [
    "tffiles = glob.glob('tfrecords/*')\n",
    "raw_image_dataset = tf.data.TFRecordDataset(tffiles)\n",
    "\n",
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def _parse_image_label(parsed_dataset):\n",
    "    return preprocess(tf.image.decode_png(parsed_dataset['image_raw'])), parsed_dataset['label']\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "dataset = parsed_image_dataset.map(_parse_image_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhJdi9Zf10Xr"
   },
   "source": [
    "Train and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ir0hQ1YhvqMm"
   },
   "outputs": [],
   "source": [
    "ds_size = 0\n",
    "for _ in dataset:\n",
    "    ds_size += 1\n",
    "\n",
    "train_size = int(ds_size * 0.7)\n",
    "\n",
    "ds = dataset.shuffle(ds_size)\n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).prefetch(1024).batch(32).map(augmentation)\n",
    "ds_valid = ds.skip(train_size).prefetch(1024).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vqo_gKN319gN"
   },
   "source": [
    "Build a model and start learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HOh_FPXvqO_"
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRbvaJuAvqR4",
    "outputId": "ea7025e9-1f98-4f2b-fc05-f0686cabbe90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "58/58 [==============================] - 70s 547ms/step - loss: 0.6938 - accuracy: 0.5261 - val_loss: 0.6901 - val_accuracy: 0.4937\n",
      "Epoch 2/1000\n",
      "58/58 [==============================] - 34s 522ms/step - loss: 0.6935 - accuracy: 0.5087 - val_loss: 0.6919 - val_accuracy: 0.5076\n",
      "Epoch 3/1000\n",
      "58/58 [==============================] - 33s 502ms/step - loss: 0.6930 - accuracy: 0.4995 - val_loss: 0.6874 - val_accuracy: 0.4987\n",
      "Epoch 4/1000\n",
      "58/58 [==============================] - 34s 504ms/step - loss: 0.6845 - accuracy: 0.5506 - val_loss: 0.6865 - val_accuracy: 0.5723\n",
      "Epoch 5/1000\n",
      "58/58 [==============================] - 34s 514ms/step - loss: 0.6871 - accuracy: 0.5256 - val_loss: 0.6854 - val_accuracy: 0.5063\n",
      "Epoch 6/1000\n",
      "58/58 [==============================] - 34s 504ms/step - loss: 0.6937 - accuracy: 0.5147 - val_loss: 0.6887 - val_accuracy: 0.6409\n",
      "Epoch 7/1000\n",
      "58/58 [==============================] - 33s 502ms/step - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6879 - val_accuracy: 0.5203\n",
      "Epoch 8/1000\n",
      "58/58 [==============================] - 34s 510ms/step - loss: 0.6889 - accuracy: 0.5370 - val_loss: 0.7002 - val_accuracy: 0.5025\n",
      "Epoch 9/1000\n",
      "58/58 [==============================] - 33s 498ms/step - loss: 0.6883 - accuracy: 0.5397 - val_loss: 1.0727 - val_accuracy: 0.5165\n",
      "Epoch 10/1000\n",
      "58/58 [==============================] - 34s 512ms/step - loss: 0.7020 - accuracy: 0.5109 - val_loss: 0.6948 - val_accuracy: 0.4480\n",
      "Epoch 11/1000\n",
      "58/58 [==============================] - 33s 490ms/step - loss: 0.6812 - accuracy: 0.5354 - val_loss: 0.6628 - val_accuracy: 0.6548\n",
      "Epoch 12/1000\n",
      "58/58 [==============================] - 35s 520ms/step - loss: 0.6881 - accuracy: 0.5109 - val_loss: 0.6914 - val_accuracy: 0.6053\n",
      "Epoch 13/1000\n",
      "58/58 [==============================] - 33s 495ms/step - loss: 0.6885 - accuracy: 0.5147 - val_loss: 0.6783 - val_accuracy: 0.5888\n",
      "Epoch 14/1000\n",
      "58/58 [==============================] - 34s 506ms/step - loss: 0.6815 - accuracy: 0.5664 - val_loss: 0.6555 - val_accuracy: 0.5787\n",
      "Epoch 15/1000\n",
      "58/58 [==============================] - 33s 507ms/step - loss: 0.6650 - accuracy: 0.5881 - val_loss: 0.6438 - val_accuracy: 0.6612\n",
      "Epoch 16/1000\n",
      "58/58 [==============================] - 32s 484ms/step - loss: 0.6824 - accuracy: 0.5375 - val_loss: 0.6582 - val_accuracy: 0.6586\n",
      "Epoch 17/1000\n",
      "58/58 [==============================] - 34s 510ms/step - loss: 0.6618 - accuracy: 0.6001 - val_loss: 0.6141 - val_accuracy: 0.6853\n",
      "Epoch 18/1000\n",
      "58/58 [==============================] - 33s 496ms/step - loss: 0.6496 - accuracy: 0.5996 - val_loss: 0.6260 - val_accuracy: 0.6675\n",
      "Epoch 19/1000\n",
      "58/58 [==============================] - 34s 514ms/step - loss: 0.6530 - accuracy: 0.5930 - val_loss: 0.6628 - val_accuracy: 0.6091\n",
      "Epoch 20/1000\n",
      "58/58 [==============================] - 33s 490ms/step - loss: 0.6640 - accuracy: 0.5484 - val_loss: 0.6167 - val_accuracy: 0.6764\n",
      "Epoch 21/1000\n",
      "58/58 [==============================] - 33s 496ms/step - loss: 0.6433 - accuracy: 0.5985 - val_loss: 0.6411 - val_accuracy: 0.6853\n",
      "Epoch 22/1000\n",
      "58/58 [==============================] - 33s 497ms/step - loss: 0.6492 - accuracy: 0.6045 - val_loss: 0.6002 - val_accuracy: 0.6574\n",
      "Epoch 23/1000\n",
      "58/58 [==============================] - 33s 491ms/step - loss: 0.6449 - accuracy: 0.6088 - val_loss: 0.6154 - val_accuracy: 0.6117\n",
      "Epoch 24/1000\n",
      "58/58 [==============================] - 33s 493ms/step - loss: 0.6581 - accuracy: 0.5615 - val_loss: 0.5975 - val_accuracy: 0.6561\n",
      "Epoch 25/1000\n",
      "58/58 [==============================] - 32s 482ms/step - loss: 0.6358 - accuracy: 0.6115 - val_loss: 0.5642 - val_accuracy: 0.7195\n",
      "Epoch 26/1000\n",
      "58/58 [==============================] - 34s 505ms/step - loss: 0.6318 - accuracy: 0.5990 - val_loss: 0.5437 - val_accuracy: 0.7538\n",
      "Epoch 27/1000\n",
      "58/58 [==============================] - 34s 519ms/step - loss: 0.6509 - accuracy: 0.5854 - val_loss: 0.5922 - val_accuracy: 0.7069\n",
      "Epoch 28/1000\n",
      "58/58 [==============================] - 33s 494ms/step - loss: 0.6338 - accuracy: 0.5996 - val_loss: 0.5952 - val_accuracy: 0.7398\n",
      "Epoch 29/1000\n",
      "58/58 [==============================] - 33s 500ms/step - loss: 0.6463 - accuracy: 0.5871 - val_loss: 0.5400 - val_accuracy: 0.7360\n",
      "Epoch 30/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.6497 - accuracy: 0.5892 - val_loss: 0.6298 - val_accuracy: 0.6802\n",
      "Epoch 31/1000\n",
      "58/58 [==============================] - 32s 479ms/step - loss: 0.6527 - accuracy: 0.5773 - val_loss: 0.5538 - val_accuracy: 0.7310\n",
      "Epoch 32/1000\n",
      "58/58 [==============================] - 33s 488ms/step - loss: 0.6402 - accuracy: 0.6186 - val_loss: 0.5983 - val_accuracy: 0.6764\n",
      "Epoch 33/1000\n",
      "58/58 [==============================] - 32s 487ms/step - loss: 0.6298 - accuracy: 0.6072 - val_loss: 0.5571 - val_accuracy: 0.7272\n",
      "Epoch 34/1000\n",
      "58/58 [==============================] - 33s 490ms/step - loss: 0.6230 - accuracy: 0.6137 - val_loss: 0.5717 - val_accuracy: 0.7018\n",
      "Epoch 35/1000\n",
      "58/58 [==============================] - 32s 484ms/step - loss: 0.6242 - accuracy: 0.6300 - val_loss: 0.5357 - val_accuracy: 0.7538\n",
      "Epoch 36/1000\n",
      "58/58 [==============================] - 33s 502ms/step - loss: 0.6327 - accuracy: 0.5930 - val_loss: 0.5702 - val_accuracy: 0.7576\n",
      "Epoch 37/1000\n",
      "58/58 [==============================] - 32s 487ms/step - loss: 0.6259 - accuracy: 0.6425 - val_loss: 0.5498 - val_accuracy: 0.7589\n",
      "Epoch 38/1000\n",
      "58/58 [==============================] - 33s 490ms/step - loss: 0.6180 - accuracy: 0.6496 - val_loss: 0.5431 - val_accuracy: 0.7360\n",
      "Epoch 39/1000\n",
      "58/58 [==============================] - 34s 509ms/step - loss: 0.6258 - accuracy: 0.6213 - val_loss: 0.5213 - val_accuracy: 0.7589\n",
      "Epoch 40/1000\n",
      "58/58 [==============================] - 33s 503ms/step - loss: 0.6304 - accuracy: 0.6317 - val_loss: 0.5640 - val_accuracy: 0.7551\n",
      "Epoch 41/1000\n",
      "58/58 [==============================] - 34s 511ms/step - loss: 0.6268 - accuracy: 0.6126 - val_loss: 0.5465 - val_accuracy: 0.7437\n",
      "Epoch 42/1000\n",
      "58/58 [==============================] - 34s 510ms/step - loss: 0.6189 - accuracy: 0.6387 - val_loss: 0.5703 - val_accuracy: 0.7069\n",
      "Epoch 43/1000\n",
      "58/58 [==============================] - 34s 504ms/step - loss: 0.6209 - accuracy: 0.6235 - val_loss: 0.5368 - val_accuracy: 0.7145\n",
      "Epoch 44/1000\n",
      "58/58 [==============================] - 34s 508ms/step - loss: 0.6318 - accuracy: 0.6170 - val_loss: 0.5874 - val_accuracy: 0.7538\n",
      "Epoch 45/1000\n",
      "58/58 [==============================] - 32s 488ms/step - loss: 0.6390 - accuracy: 0.6159 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 46/1000\n",
      "58/58 [==============================] - 35s 524ms/step - loss: 0.6638 - accuracy: 0.6153 - val_loss: 0.5381 - val_accuracy: 0.7310\n",
      "Epoch 47/1000\n",
      "58/58 [==============================] - 34s 506ms/step - loss: 0.6185 - accuracy: 0.6224 - val_loss: 0.5884 - val_accuracy: 0.6409\n",
      "Epoch 48/1000\n",
      "58/58 [==============================] - 33s 494ms/step - loss: 0.6349 - accuracy: 0.6197 - val_loss: 0.5039 - val_accuracy: 0.7576\n",
      "Epoch 49/1000\n",
      "58/58 [==============================] - 33s 497ms/step - loss: 0.6231 - accuracy: 0.6262 - val_loss: 0.5116 - val_accuracy: 0.7741\n",
      "Epoch 50/1000\n",
      "58/58 [==============================] - 33s 501ms/step - loss: 0.6338 - accuracy: 0.5985 - val_loss: 0.5063 - val_accuracy: 0.7741\n",
      "Epoch 51/1000\n",
      "58/58 [==============================] - 32s 485ms/step - loss: 0.6066 - accuracy: 0.6208 - val_loss: 0.5087 - val_accuracy: 0.7652\n",
      "Epoch 52/1000\n",
      "58/58 [==============================] - 33s 489ms/step - loss: 0.5843 - accuracy: 0.6665 - val_loss: 0.4794 - val_accuracy: 0.7690\n",
      "Epoch 53/1000\n",
      "58/58 [==============================] - 32s 476ms/step - loss: 0.5956 - accuracy: 0.6496 - val_loss: 0.5256 - val_accuracy: 0.7627\n",
      "Epoch 54/1000\n",
      "58/58 [==============================] - 32s 477ms/step - loss: 0.5691 - accuracy: 0.6888 - val_loss: 0.4940 - val_accuracy: 0.7779\n",
      "Epoch 55/1000\n",
      "58/58 [==============================] - 33s 490ms/step - loss: 0.6355 - accuracy: 0.6257 - val_loss: 0.6095 - val_accuracy: 0.6853\n",
      "Epoch 56/1000\n",
      "58/58 [==============================] - 32s 484ms/step - loss: 0.6263 - accuracy: 0.6376 - val_loss: 0.5176 - val_accuracy: 0.7690\n",
      "Epoch 57/1000\n",
      "58/58 [==============================] - 32s 490ms/step - loss: 0.6192 - accuracy: 0.6279 - val_loss: 0.5230 - val_accuracy: 0.7221\n",
      "Epoch 58/1000\n",
      "58/58 [==============================] - 34s 505ms/step - loss: 0.5955 - accuracy: 0.6485 - val_loss: 0.5118 - val_accuracy: 0.7589\n",
      "Epoch 59/1000\n",
      "58/58 [==============================] - 34s 508ms/step - loss: 0.6097 - accuracy: 0.6333 - val_loss: 0.5106 - val_accuracy: 0.7538\n",
      "Epoch 60/1000\n",
      "58/58 [==============================] - 34s 517ms/step - loss: 0.6095 - accuracy: 0.6322 - val_loss: 0.5115 - val_accuracy: 0.7525\n",
      "Epoch 61/1000\n",
      "58/58 [==============================] - 33s 496ms/step - loss: 0.5954 - accuracy: 0.6311 - val_loss: 0.4538 - val_accuracy: 0.7766\n",
      "Epoch 62/1000\n",
      "58/58 [==============================] - 32s 474ms/step - loss: 0.5901 - accuracy: 0.6453 - val_loss: 0.4784 - val_accuracy: 0.7766\n",
      "Epoch 63/1000\n",
      "58/58 [==============================] - 34s 521ms/step - loss: 0.6023 - accuracy: 0.6251 - val_loss: 0.4884 - val_accuracy: 0.7652\n",
      "Epoch 64/1000\n",
      "58/58 [==============================] - 34s 504ms/step - loss: 0.6084 - accuracy: 0.6066 - val_loss: 0.5105 - val_accuracy: 0.7805\n",
      "Epoch 65/1000\n",
      "58/58 [==============================] - 32s 483ms/step - loss: 0.6003 - accuracy: 0.6366 - val_loss: 0.4739 - val_accuracy: 0.7817\n",
      "Epoch 66/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.6082 - accuracy: 0.6322 - val_loss: 0.4762 - val_accuracy: 0.7703\n",
      "Epoch 67/1000\n",
      "58/58 [==============================] - 34s 506ms/step - loss: 0.5947 - accuracy: 0.6425 - val_loss: 0.4718 - val_accuracy: 0.7703\n",
      "Epoch 68/1000\n",
      "58/58 [==============================] - 34s 510ms/step - loss: 0.5848 - accuracy: 0.6376 - val_loss: 0.4296 - val_accuracy: 0.7893\n",
      "Epoch 69/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.5887 - accuracy: 0.6480 - val_loss: 0.4576 - val_accuracy: 0.7728\n",
      "Epoch 70/1000\n",
      "58/58 [==============================] - 33s 507ms/step - loss: 0.5943 - accuracy: 0.6240 - val_loss: 0.4630 - val_accuracy: 0.7703\n",
      "Epoch 71/1000\n",
      "58/58 [==============================] - 32s 488ms/step - loss: 0.5668 - accuracy: 0.6578 - val_loss: 0.4467 - val_accuracy: 0.7690\n",
      "Epoch 72/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.5836 - accuracy: 0.6523 - val_loss: 0.4786 - val_accuracy: 0.7627\n",
      "Epoch 73/1000\n",
      "58/58 [==============================] - 33s 498ms/step - loss: 0.5980 - accuracy: 0.6017 - val_loss: 0.4148 - val_accuracy: 0.8020\n",
      "Epoch 74/1000\n",
      "58/58 [==============================] - 34s 518ms/step - loss: 0.5859 - accuracy: 0.6398 - val_loss: 0.4549 - val_accuracy: 0.7665\n",
      "Epoch 75/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.5701 - accuracy: 0.6376 - val_loss: 0.4251 - val_accuracy: 0.7678\n",
      "Epoch 76/1000\n",
      "58/58 [==============================] - 33s 505ms/step - loss: 0.5744 - accuracy: 0.6360 - val_loss: 0.5738 - val_accuracy: 0.7602\n",
      "Epoch 77/1000\n",
      "58/58 [==============================] - 33s 488ms/step - loss: 0.5425 - accuracy: 0.6730 - val_loss: 0.5869 - val_accuracy: 0.7424\n",
      "Epoch 78/1000\n",
      "58/58 [==============================] - 32s 486ms/step - loss: 0.5890 - accuracy: 0.6300 - val_loss: 0.4779 - val_accuracy: 0.7779\n",
      "Epoch 79/1000\n",
      "58/58 [==============================] - 33s 494ms/step - loss: 0.5854 - accuracy: 0.6360 - val_loss: 0.4214 - val_accuracy: 0.7690\n",
      "Epoch 80/1000\n",
      "58/58 [==============================] - 33s 493ms/step - loss: 0.5755 - accuracy: 0.6474 - val_loss: 0.4046 - val_accuracy: 0.7944\n",
      "Epoch 81/1000\n",
      "58/58 [==============================] - 33s 492ms/step - loss: 0.6155 - accuracy: 0.6001 - val_loss: 0.5451 - val_accuracy: 0.6992\n",
      "Epoch 82/1000\n",
      "58/58 [==============================] - 34s 514ms/step - loss: 0.6493 - accuracy: 0.5550 - val_loss: 0.5187 - val_accuracy: 0.7310\n",
      "Epoch 83/1000\n",
      "58/58 [==============================] - 33s 494ms/step - loss: 0.6006 - accuracy: 0.6398 - val_loss: 0.4725 - val_accuracy: 0.7665\n",
      "Epoch 84/1000\n",
      "58/58 [==============================] - 33s 488ms/step - loss: 0.5474 - accuracy: 0.6741 - val_loss: 0.4499 - val_accuracy: 0.7982\n",
      "Epoch 85/1000\n",
      "58/58 [==============================] - 33s 501ms/step - loss: 0.5868 - accuracy: 0.6208 - val_loss: 0.4213 - val_accuracy: 0.7805\n",
      "Epoch 86/1000\n",
      "58/58 [==============================] - 33s 495ms/step - loss: 0.5858 - accuracy: 0.6338 - val_loss: 0.4892 - val_accuracy: 0.7525\n",
      "Epoch 87/1000\n",
      "58/58 [==============================] - 34s 509ms/step - loss: 0.5641 - accuracy: 0.6502 - val_loss: 0.4112 - val_accuracy: 0.7855\n",
      "Epoch 88/1000\n",
      "58/58 [==============================] - 36s 540ms/step - loss: 0.5950 - accuracy: 0.6126 - val_loss: 0.4618 - val_accuracy: 0.7995\n",
      "Epoch 89/1000\n",
      "58/58 [==============================] - 34s 512ms/step - loss: 0.5836 - accuracy: 0.6300 - val_loss: 0.4284 - val_accuracy: 0.8147\n",
      "Epoch 90/1000\n",
      "58/58 [==============================] - 33s 491ms/step - loss: 0.5717 - accuracy: 0.6523 - val_loss: 0.5070 - val_accuracy: 0.7652\n",
      "Epoch 91/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.6156 - accuracy: 0.5979 - val_loss: 0.4417 - val_accuracy: 0.7919\n",
      "Epoch 92/1000\n",
      "58/58 [==============================] - 33s 503ms/step - loss: 0.5805 - accuracy: 0.6186 - val_loss: 0.4389 - val_accuracy: 0.7766\n",
      "Epoch 93/1000\n",
      "58/58 [==============================] - 33s 487ms/step - loss: 0.5416 - accuracy: 0.6632 - val_loss: 0.4269 - val_accuracy: 0.8046\n",
      "Epoch 94/1000\n",
      "58/58 [==============================] - 34s 507ms/step - loss: 0.5977 - accuracy: 0.6344 - val_loss: 0.4651 - val_accuracy: 0.7830\n",
      "Epoch 95/1000\n",
      "58/58 [==============================] - 34s 513ms/step - loss: 0.5813 - accuracy: 0.6159 - val_loss: 0.3928 - val_accuracy: 0.7970\n",
      "Epoch 96/1000\n",
      "58/58 [==============================] - 33s 491ms/step - loss: 0.5483 - accuracy: 0.6692 - val_loss: 0.4032 - val_accuracy: 0.8008\n",
      "Epoch 97/1000\n",
      "58/58 [==============================] - 32s 479ms/step - loss: 0.5242 - accuracy: 0.6855 - val_loss: 0.3887 - val_accuracy: 0.8096\n",
      "Epoch 98/1000\n",
      "58/58 [==============================] - 33s 498ms/step - loss: 0.5743 - accuracy: 0.6300 - val_loss: 0.3953 - val_accuracy: 0.8363\n",
      "Epoch 99/1000\n",
      "58/58 [==============================] - 32s 478ms/step - loss: 0.5674 - accuracy: 0.6605 - val_loss: 0.3729 - val_accuracy: 0.8185\n",
      "Epoch 100/1000\n",
      "58/58 [==============================] - 34s 518ms/step - loss: 0.5909 - accuracy: 0.6322 - val_loss: 0.3811 - val_accuracy: 0.8338\n",
      "Epoch 101/1000\n",
      "58/58 [==============================] - 33s 492ms/step - loss: 0.5502 - accuracy: 0.6513 - val_loss: 0.3619 - val_accuracy: 0.8274\n",
      "Epoch 102/1000\n",
      "58/58 [==============================] - 33s 491ms/step - loss: 0.5564 - accuracy: 0.6556 - val_loss: 0.3546 - val_accuracy: 0.8439\n",
      "Epoch 103/1000\n",
      "58/58 [==============================] - 34s 514ms/step - loss: 0.5469 - accuracy: 0.6474 - val_loss: 0.4209 - val_accuracy: 0.7817\n",
      "Epoch 104/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.5592 - accuracy: 0.6502 - val_loss: 0.3833 - val_accuracy: 0.8147\n",
      "Epoch 105/1000\n",
      "58/58 [==============================] - 34s 514ms/step - loss: 0.5772 - accuracy: 0.6148 - val_loss: 0.3661 - val_accuracy: 0.8135\n",
      "Epoch 106/1000\n",
      "58/58 [==============================] - 33s 491ms/step - loss: 0.5462 - accuracy: 0.6556 - val_loss: 0.3621 - val_accuracy: 0.8363\n",
      "Epoch 107/1000\n",
      "58/58 [==============================] - 34s 506ms/step - loss: 0.5450 - accuracy: 0.6621 - val_loss: 0.4150 - val_accuracy: 0.7995\n",
      "Epoch 108/1000\n",
      "58/58 [==============================] - 34s 503ms/step - loss: 0.6153 - accuracy: 0.6012 - val_loss: 0.4540 - val_accuracy: 0.7931\n",
      "Epoch 109/1000\n",
      "58/58 [==============================] - 34s 506ms/step - loss: 0.5774 - accuracy: 0.6507 - val_loss: 0.4562 - val_accuracy: 0.7855\n",
      "Epoch 110/1000\n",
      "58/58 [==============================] - 34s 512ms/step - loss: 0.5502 - accuracy: 0.6583 - val_loss: 0.3977 - val_accuracy: 0.8198\n",
      "Epoch 111/1000\n",
      "58/58 [==============================] - 34s 508ms/step - loss: 0.5333 - accuracy: 0.6643 - val_loss: 0.3679 - val_accuracy: 0.8579\n",
      "Epoch 112/1000\n",
      "58/58 [==============================] - 34s 518ms/step - loss: 0.5673 - accuracy: 0.6556 - val_loss: 0.4779 - val_accuracy: 0.7259\n",
      "Epoch 113/1000\n",
      "58/58 [==============================] - 32s 471ms/step - loss: 0.5451 - accuracy: 0.6697 - val_loss: 0.4523 - val_accuracy: 0.7779\n",
      "Epoch 114/1000\n",
      "58/58 [==============================] - 34s 515ms/step - loss: 0.5673 - accuracy: 0.6507 - val_loss: 0.3655 - val_accuracy: 0.8693\n",
      "Epoch 115/1000\n",
      "58/58 [==============================] - 33s 497ms/step - loss: 0.5623 - accuracy: 0.6262 - val_loss: 0.3844 - val_accuracy: 0.8464\n",
      "Epoch 116/1000\n",
      "58/58 [==============================] - 35s 522ms/step - loss: 0.5651 - accuracy: 0.6279 - val_loss: 0.3203 - val_accuracy: 0.8642\n",
      "Epoch 117/1000\n",
      "58/58 [==============================] - 34s 517ms/step - loss: 0.5607 - accuracy: 0.6382 - val_loss: 0.4405 - val_accuracy: 0.7931\n",
      "Epoch 118/1000\n",
      "58/58 [==============================] - 34s 518ms/step - loss: 0.6065 - accuracy: 0.6251 - val_loss: 0.4438 - val_accuracy: 0.7995\n",
      "Epoch 119/1000\n",
      "58/58 [==============================] - 34s 505ms/step - loss: 0.5646 - accuracy: 0.6621 - val_loss: 0.4249 - val_accuracy: 0.8198\n",
      "Epoch 120/1000\n",
      "58/58 [==============================] - 33s 502ms/step - loss: 0.5301 - accuracy: 0.6801 - val_loss: 0.4560 - val_accuracy: 0.8249\n",
      "Epoch 121/1000\n",
      "58/58 [==============================] - 33s 505ms/step - loss: 0.5480 - accuracy: 0.6638 - val_loss: 0.3211 - val_accuracy: 0.8668\n",
      "Epoch 122/1000\n",
      "58/58 [==============================] - 33s 498ms/step - loss: 0.5310 - accuracy: 0.6649 - val_loss: 0.4186 - val_accuracy: 0.8096\n",
      "Epoch 123/1000\n",
      "58/58 [==============================] - 32s 485ms/step - loss: 0.5484 - accuracy: 0.6741 - val_loss: 0.3165 - val_accuracy: 0.8744\n",
      "Epoch 124/1000\n",
      "58/58 [==============================] - 33s 498ms/step - loss: 0.5194 - accuracy: 0.6730 - val_loss: 0.3165 - val_accuracy: 0.8629\n",
      "Epoch 125/1000\n",
      "58/58 [==============================] - 32s 476ms/step - loss: 0.5163 - accuracy: 0.6942 - val_loss: 0.3375 - val_accuracy: 0.8579\n",
      "Epoch 126/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.5275 - accuracy: 0.6746 - val_loss: 0.3942 - val_accuracy: 0.8541\n",
      "Epoch 127/1000\n",
      "58/58 [==============================] - 34s 516ms/step - loss: 0.5212 - accuracy: 0.6507 - val_loss: 0.2902 - val_accuracy: 0.8832\n",
      "Epoch 128/1000\n",
      "58/58 [==============================] - 33s 502ms/step - loss: 0.5034 - accuracy: 0.6872 - val_loss: 0.2487 - val_accuracy: 0.9010\n",
      "Epoch 129/1000\n",
      "58/58 [==============================] - 34s 511ms/step - loss: 0.5234 - accuracy: 0.6980 - val_loss: 0.5745 - val_accuracy: 0.7462\n",
      "Epoch 130/1000\n",
      "58/58 [==============================] - 34s 516ms/step - loss: 0.5767 - accuracy: 0.6436 - val_loss: 0.3549 - val_accuracy: 0.8820\n",
      "Epoch 131/1000\n",
      "58/58 [==============================] - 34s 519ms/step - loss: 0.4976 - accuracy: 0.6888 - val_loss: 0.3101 - val_accuracy: 0.8896\n",
      "Epoch 132/1000\n",
      "58/58 [==============================] - 34s 507ms/step - loss: 0.4798 - accuracy: 0.7209 - val_loss: 0.2674 - val_accuracy: 0.8985\n",
      "Epoch 133/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.5121 - accuracy: 0.6850 - val_loss: 0.2525 - val_accuracy: 0.8959\n",
      "Epoch 134/1000\n",
      "58/58 [==============================] - 34s 517ms/step - loss: 0.5116 - accuracy: 0.6980 - val_loss: 0.2803 - val_accuracy: 0.9036\n",
      "Epoch 135/1000\n",
      "58/58 [==============================] - 32s 484ms/step - loss: 0.5248 - accuracy: 0.6714 - val_loss: 0.2065 - val_accuracy: 0.9264\n",
      "Epoch 136/1000\n",
      "58/58 [==============================] - 34s 519ms/step - loss: 0.5224 - accuracy: 0.6741 - val_loss: 0.3632 - val_accuracy: 0.8604\n",
      "Epoch 137/1000\n",
      "58/58 [==============================] - 34s 521ms/step - loss: 0.4820 - accuracy: 0.7133 - val_loss: 0.2343 - val_accuracy: 0.9099\n",
      "Epoch 138/1000\n",
      "58/58 [==============================] - 33s 497ms/step - loss: 0.4647 - accuracy: 0.7160 - val_loss: 0.2446 - val_accuracy: 0.9099\n",
      "Epoch 139/1000\n",
      "58/58 [==============================] - 34s 509ms/step - loss: 0.5100 - accuracy: 0.6774 - val_loss: 0.2152 - val_accuracy: 0.9264\n",
      "Epoch 140/1000\n",
      "58/58 [==============================] - 34s 509ms/step - loss: 0.4876 - accuracy: 0.6948 - val_loss: 0.2240 - val_accuracy: 0.9124\n",
      "Epoch 141/1000\n",
      "58/58 [==============================] - 35s 521ms/step - loss: 0.5208 - accuracy: 0.6736 - val_loss: 0.2751 - val_accuracy: 0.8959\n",
      "Epoch 142/1000\n",
      "58/58 [==============================] - 33s 493ms/step - loss: 0.5215 - accuracy: 0.6763 - val_loss: 0.1861 - val_accuracy: 0.9353\n",
      "Epoch 143/1000\n",
      "58/58 [==============================] - 33s 492ms/step - loss: 0.4573 - accuracy: 0.7193 - val_loss: 0.2903 - val_accuracy: 0.8794\n",
      "Epoch 144/1000\n",
      "58/58 [==============================] - 34s 510ms/step - loss: 0.4711 - accuracy: 0.7160 - val_loss: 0.2530 - val_accuracy: 0.9061\n",
      "Epoch 145/1000\n",
      "58/58 [==============================] - 34s 518ms/step - loss: 0.5067 - accuracy: 0.6828 - val_loss: 0.2352 - val_accuracy: 0.8997\n",
      "Epoch 146/1000\n",
      "58/58 [==============================] - 33s 496ms/step - loss: 0.4959 - accuracy: 0.6921 - val_loss: 0.2376 - val_accuracy: 0.9137\n",
      "Epoch 147/1000\n",
      "58/58 [==============================] - 32s 473ms/step - loss: 0.4391 - accuracy: 0.7339 - val_loss: 0.2309 - val_accuracy: 0.9150\n",
      "Epoch 148/1000\n",
      "58/58 [==============================] - 33s 489ms/step - loss: 0.5134 - accuracy: 0.6768 - val_loss: 0.2459 - val_accuracy: 0.9099\n",
      "Epoch 149/1000\n",
      "58/58 [==============================] - 35s 531ms/step - loss: 0.5112 - accuracy: 0.6790 - val_loss: 0.2252 - val_accuracy: 0.9086\n",
      "Epoch 150/1000\n",
      "58/58 [==============================] - 32s 486ms/step - loss: 0.4445 - accuracy: 0.7356 - val_loss: 0.2276 - val_accuracy: 0.9239\n",
      "Epoch 151/1000\n",
      "58/58 [==============================] - 33s 501ms/step - loss: 0.4611 - accuracy: 0.7193 - val_loss: 0.2083 - val_accuracy: 0.9277\n",
      "Epoch 152/1000\n",
      "58/58 [==============================] - 34s 514ms/step - loss: 0.4963 - accuracy: 0.7013 - val_loss: 0.2099 - val_accuracy: 0.9074\n",
      "Epoch 153/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.4584 - accuracy: 0.7149 - val_loss: 0.1910 - val_accuracy: 0.9213\n",
      "Epoch 154/1000\n",
      "58/58 [==============================] - 33s 505ms/step - loss: 0.4365 - accuracy: 0.7394 - val_loss: 0.1975 - val_accuracy: 0.9162\n",
      "Epoch 155/1000\n",
      "58/58 [==============================] - 33s 489ms/step - loss: 0.4197 - accuracy: 0.7361 - val_loss: 0.2042 - val_accuracy: 0.9226\n",
      "Epoch 156/1000\n",
      "58/58 [==============================] - 34s 511ms/step - loss: 0.4574 - accuracy: 0.7274 - val_loss: 0.2051 - val_accuracy: 0.9226\n",
      "Epoch 157/1000\n",
      "58/58 [==============================] - 34s 507ms/step - loss: 0.4566 - accuracy: 0.7182 - val_loss: 0.1980 - val_accuracy: 0.9188\n",
      "Epoch 158/1000\n",
      "58/58 [==============================] - 32s 480ms/step - loss: 0.4276 - accuracy: 0.7361 - val_loss: 0.1838 - val_accuracy: 0.9315\n",
      "Epoch 159/1000\n",
      "58/58 [==============================] - 33s 496ms/step - loss: 0.4512 - accuracy: 0.7301 - val_loss: 0.1947 - val_accuracy: 0.9289\n",
      "Epoch 160/1000\n",
      "58/58 [==============================] - 33s 495ms/step - loss: 0.4550 - accuracy: 0.7116 - val_loss: 0.2224 - val_accuracy: 0.9099\n",
      "Epoch 161/1000\n",
      "58/58 [==============================] - 33s 496ms/step - loss: 0.4377 - accuracy: 0.7291 - val_loss: 0.1968 - val_accuracy: 0.9239\n",
      "Epoch 162/1000\n",
      "58/58 [==============================] - 34s 508ms/step - loss: 0.4837 - accuracy: 0.6980 - val_loss: 0.2047 - val_accuracy: 0.9201\n",
      "Epoch 163/1000\n",
      "58/58 [==============================] - 34s 513ms/step - loss: 0.4286 - accuracy: 0.7291 - val_loss: 0.1625 - val_accuracy: 0.9365\n",
      "Epoch 164/1000\n",
      "58/58 [==============================] - 34s 520ms/step - loss: 0.4779 - accuracy: 0.6986 - val_loss: 0.1881 - val_accuracy: 0.9340\n",
      "Epoch 165/1000\n",
      "58/58 [==============================] - 34s 506ms/step - loss: 0.4768 - accuracy: 0.7111 - val_loss: 0.1488 - val_accuracy: 0.9530\n",
      "Epoch 166/1000\n",
      "58/58 [==============================] - 34s 510ms/step - loss: 0.4412 - accuracy: 0.7144 - val_loss: 0.2037 - val_accuracy: 0.9188\n",
      "Epoch 167/1000\n",
      "58/58 [==============================] - 35s 525ms/step - loss: 0.5103 - accuracy: 0.6882 - val_loss: 0.1701 - val_accuracy: 0.9327\n",
      "Epoch 168/1000\n",
      "58/58 [==============================] - 34s 518ms/step - loss: 0.4813 - accuracy: 0.6910 - val_loss: 0.2170 - val_accuracy: 0.9112\n",
      "Epoch 169/1000\n",
      "58/58 [==============================] - 34s 505ms/step - loss: 0.4690 - accuracy: 0.7013 - val_loss: 0.1597 - val_accuracy: 0.9365\n",
      "Epoch 170/1000\n",
      "58/58 [==============================] - 34s 508ms/step - loss: 0.4264 - accuracy: 0.7345 - val_loss: 0.1940 - val_accuracy: 0.9289\n",
      "Epoch 171/1000\n",
      "58/58 [==============================] - 32s 474ms/step - loss: 0.3941 - accuracy: 0.7519 - val_loss: 0.1960 - val_accuracy: 0.9226\n",
      "Epoch 172/1000\n",
      "58/58 [==============================] - 34s 512ms/step - loss: 0.4603 - accuracy: 0.7073 - val_loss: 0.1582 - val_accuracy: 0.9442\n",
      "Epoch 173/1000\n",
      "58/58 [==============================] - 34s 511ms/step - loss: 0.5019 - accuracy: 0.6719 - val_loss: 0.2089 - val_accuracy: 0.9150\n",
      "Epoch 174/1000\n",
      "58/58 [==============================] - 34s 507ms/step - loss: 0.4760 - accuracy: 0.6964 - val_loss: 0.1662 - val_accuracy: 0.9365\n",
      "Epoch 175/1000\n",
      "58/58 [==============================] - 34s 521ms/step - loss: 0.4855 - accuracy: 0.6774 - val_loss: 0.1573 - val_accuracy: 0.9365\n",
      "Epoch 176/1000\n",
      "58/58 [==============================] - 34s 522ms/step - loss: 0.5159 - accuracy: 0.6491 - val_loss: 0.1599 - val_accuracy: 0.9277\n",
      "Epoch 177/1000\n",
      "58/58 [==============================] - 34s 515ms/step - loss: 0.4855 - accuracy: 0.6801 - val_loss: 0.1687 - val_accuracy: 0.9226\n",
      "Epoch 178/1000\n",
      "58/58 [==============================] - 33s 495ms/step - loss: 0.4927 - accuracy: 0.6730 - val_loss: 0.2105 - val_accuracy: 0.9251\n",
      "Epoch 179/1000\n",
      "58/58 [==============================] - 34s 515ms/step - loss: 0.4485 - accuracy: 0.7203 - val_loss: 0.2380 - val_accuracy: 0.9188\n",
      "Epoch 180/1000\n",
      "58/58 [==============================] - 34s 509ms/step - loss: 0.4757 - accuracy: 0.6828 - val_loss: 0.1451 - val_accuracy: 0.9365\n",
      "Epoch 181/1000\n",
      "58/58 [==============================] - 34s 511ms/step - loss: 0.4412 - accuracy: 0.7122 - val_loss: 0.1556 - val_accuracy: 0.9378\n",
      "Epoch 182/1000\n",
      "58/58 [==============================] - 33s 488ms/step - loss: 0.3962 - accuracy: 0.7476 - val_loss: 0.1471 - val_accuracy: 0.9277\n",
      "Epoch 183/1000\n",
      "58/58 [==============================] - 34s 519ms/step - loss: 0.4665 - accuracy: 0.6882 - val_loss: 0.1448 - val_accuracy: 0.9327\n",
      "Epoch 184/1000\n",
      "58/58 [==============================] - 34s 503ms/step - loss: 0.4789 - accuracy: 0.6752 - val_loss: 0.1620 - val_accuracy: 0.9429\n",
      "Epoch 185/1000\n",
      "58/58 [==============================] - 33s 501ms/step - loss: 0.4500 - accuracy: 0.7209 - val_loss: 0.1480 - val_accuracy: 0.9327\n",
      "Epoch 186/1000\n",
      "58/58 [==============================] - 34s 517ms/step - loss: 0.4049 - accuracy: 0.7470 - val_loss: 0.1133 - val_accuracy: 0.9683\n",
      "Epoch 187/1000\n",
      "58/58 [==============================] - 33s 490ms/step - loss: 0.4261 - accuracy: 0.6986 - val_loss: 0.1649 - val_accuracy: 0.9353\n",
      "Epoch 188/1000\n",
      "58/58 [==============================] - 33s 493ms/step - loss: 0.4535 - accuracy: 0.7334 - val_loss: 0.2222 - val_accuracy: 0.9112\n",
      "Epoch 189/1000\n",
      "58/58 [==============================] - 34s 514ms/step - loss: 0.4292 - accuracy: 0.7296 - val_loss: 0.1522 - val_accuracy: 0.9429\n",
      "Epoch 190/1000\n",
      "58/58 [==============================] - 33s 501ms/step - loss: 0.4600 - accuracy: 0.7018 - val_loss: 0.1763 - val_accuracy: 0.9175\n",
      "Epoch 191/1000\n",
      "58/58 [==============================] - 35s 526ms/step - loss: 0.5062 - accuracy: 0.6556 - val_loss: 0.1464 - val_accuracy: 0.9353\n",
      "Epoch 192/1000\n",
      "58/58 [==============================] - 33s 492ms/step - loss: 0.4000 - accuracy: 0.7361 - val_loss: 0.1456 - val_accuracy: 0.9302\n",
      "Epoch 193/1000\n",
      "58/58 [==============================] - 34s 519ms/step - loss: 0.4716 - accuracy: 0.7040 - val_loss: 0.1769 - val_accuracy: 0.9277\n",
      "Epoch 194/1000\n",
      "58/58 [==============================] - 34s 504ms/step - loss: 0.4226 - accuracy: 0.7116 - val_loss: 0.0975 - val_accuracy: 0.9632\n",
      "Epoch 195/1000\n",
      "58/58 [==============================] - 33s 501ms/step - loss: 0.3682 - accuracy: 0.7655 - val_loss: 0.0908 - val_accuracy: 0.9683\n",
      "Epoch 196/1000\n",
      "58/58 [==============================] - 35s 524ms/step - loss: 0.4775 - accuracy: 0.6687 - val_loss: 0.1230 - val_accuracy: 0.9543\n",
      "Epoch 197/1000\n",
      "58/58 [==============================] - 33s 502ms/step - loss: 0.4637 - accuracy: 0.6964 - val_loss: 0.1144 - val_accuracy: 0.9657\n",
      "Epoch 198/1000\n",
      "58/58 [==============================] - 32s 483ms/step - loss: 0.4003 - accuracy: 0.7448 - val_loss: 0.1504 - val_accuracy: 0.9492\n",
      "Epoch 199/1000\n",
      "58/58 [==============================] - 33s 489ms/step - loss: 0.3251 - accuracy: 0.7922 - val_loss: 0.1286 - val_accuracy: 0.9632\n",
      "Epoch 200/1000\n",
      "58/58 [==============================] - 33s 500ms/step - loss: 0.4912 - accuracy: 0.6850 - val_loss: 0.0936 - val_accuracy: 0.9759\n",
      "Epoch 201/1000\n",
      "58/58 [==============================] - 34s 518ms/step - loss: 0.4796 - accuracy: 0.6915 - val_loss: 0.0794 - val_accuracy: 0.9784\n",
      "Epoch 202/1000\n",
      "58/58 [==============================] - 33s 495ms/step - loss: 0.3692 - accuracy: 0.7644 - val_loss: 0.0782 - val_accuracy: 0.9810\n",
      "Epoch 203/1000\n",
      "58/58 [==============================] - 34s 508ms/step - loss: 0.4074 - accuracy: 0.7356 - val_loss: 0.0691 - val_accuracy: 0.9810\n",
      "Epoch 204/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.4397 - accuracy: 0.7035 - val_loss: 0.0855 - val_accuracy: 0.9784\n",
      "Epoch 205/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.3904 - accuracy: 0.7503 - val_loss: 0.1620 - val_accuracy: 0.9480\n",
      "Epoch 206/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.4978 - accuracy: 0.6779 - val_loss: 0.1221 - val_accuracy: 0.9619\n",
      "Epoch 207/1000\n",
      "58/58 [==============================] - 34s 524ms/step - loss: 0.4129 - accuracy: 0.7247 - val_loss: 0.0785 - val_accuracy: 0.9721\n",
      "Epoch 208/1000\n",
      "58/58 [==============================] - 32s 487ms/step - loss: 0.3961 - accuracy: 0.7514 - val_loss: 0.0861 - val_accuracy: 0.9708\n",
      "Epoch 209/1000\n",
      "58/58 [==============================] - 34s 515ms/step - loss: 0.4443 - accuracy: 0.7144 - val_loss: 0.0802 - val_accuracy: 0.9721\n",
      "Epoch 210/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.4174 - accuracy: 0.7383 - val_loss: 0.0877 - val_accuracy: 0.9708\n",
      "Epoch 211/1000\n",
      "58/58 [==============================] - 33s 494ms/step - loss: 0.4114 - accuracy: 0.7231 - val_loss: 0.1088 - val_accuracy: 0.9645\n",
      "Epoch 212/1000\n",
      "58/58 [==============================] - 33s 499ms/step - loss: 0.4145 - accuracy: 0.7350 - val_loss: 0.1099 - val_accuracy: 0.9657\n",
      "Epoch 213/1000\n",
      "58/58 [==============================] - 33s 490ms/step - loss: 0.4025 - accuracy: 0.7470 - val_loss: 0.0861 - val_accuracy: 0.9670\n",
      "Epoch 214/1000\n",
      "58/58 [==============================] - 34s 505ms/step - loss: 0.4837 - accuracy: 0.7122 - val_loss: 0.1860 - val_accuracy: 0.9442\n",
      "Epoch 215/1000\n",
      "58/58 [==============================] - 33s 494ms/step - loss: 0.3764 - accuracy: 0.7688 - val_loss: 0.0706 - val_accuracy: 0.9784\n",
      "Epoch 216/1000\n",
      "58/58 [==============================] - 32s 481ms/step - loss: 0.3063 - accuracy: 0.8139 - val_loss: 0.0720 - val_accuracy: 0.9759\n",
      "Epoch 217/1000\n",
      "58/58 [==============================] - 34s 507ms/step - loss: 0.4189 - accuracy: 0.7301 - val_loss: 0.0913 - val_accuracy: 0.9683\n",
      "Epoch 218/1000\n",
      "58/58 [==============================] - 33s 500ms/step - loss: 0.3585 - accuracy: 0.7753 - val_loss: 0.0990 - val_accuracy: 0.9645\n",
      "Epoch 219/1000\n",
      "58/58 [==============================] - 35s 526ms/step - loss: 0.5111 - accuracy: 0.6997 - val_loss: 0.1865 - val_accuracy: 0.9315\n",
      "Epoch 220/1000\n",
      "58/58 [==============================] - 33s 498ms/step - loss: 0.4566 - accuracy: 0.7029 - val_loss: 0.1355 - val_accuracy: 0.9289\n",
      "Epoch 221/1000\n",
      "58/58 [==============================] - 34s 524ms/step - loss: 0.4555 - accuracy: 0.6964 - val_loss: 0.0922 - val_accuracy: 0.9708\n",
      "Epoch 222/1000\n",
      "58/58 [==============================] - 34s 507ms/step - loss: 0.4458 - accuracy: 0.6980 - val_loss: 0.0988 - val_accuracy: 0.9721\n",
      "Epoch 223/1000\n",
      "58/58 [==============================] - 33s 504ms/step - loss: 0.3759 - accuracy: 0.7557 - val_loss: 0.0895 - val_accuracy: 0.9708\n",
      "Epoch 00223: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "history = model.fit(ds_train,\n",
    "                    validation_data=ds_valid,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aBpmz7g2LsX"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "76GF5V7KvqVN",
    "outputId": "4a8e5ef4-44be-42b5-8fe0-2317952cc6f7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.figure()\n",
    "plt.plot(loss, 'ro-', label='trn loss')\n",
    "plt.plot(val_loss, 'bo-' , label='val loss')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlpMth6_F0X6"
   },
   "source": [
    "- the learning stopped at 223 epoch.\n",
    "- The result\n",
    "  * trn_loss: 0.3759\n",
    "  * trn_accuracy: 0.7557\n",
    "  * val_loss: 0.0895\n",
    "  * val_accuracy: 0.9708"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "의류직물 불량 이미지 분석.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
